# GLM-4.6V 多模态聊天应用使用指南

## ✅ 当前功能状态

### 已实现功能
1. **图片分析**（Base64）
   - ✅ 支持 JPG、PNG、GIF 等常见格式
   - ✅ 自动转换为 `data:image/xxx;base64,...` 格式
   - ✅ 前端限制 5MB（避免超出 API 限制）
   - ✅ 后端直接传递完整 Base64 给 GLM-4.6V

2. **文档分析**（文本提取）
   - ✅ 支持 DOCX 格式（使用 mammoth 提取文本）
   - ⚠️ PDF 暂不支持（需要添加 pdf-parse）
   - ✅ 提取的文本作为 `text` 类型发送给模型

3. **流式响应**
   - ✅ SSE 流式传输
   - ✅ 实时显示 AI 回答
   - ✅ 支持中断生成

## 🚀 快速启动

### 1. 配置 API Key
编辑 `server/.env`：
```env
GLM_API_KEY=你的智谱AI密钥
PORT=3001
```

### 2. 安装依赖
```powershell
# 前端
npm install

# 后端
cd server
npm install
cd ..
```

### 3. 启动服务
```powershell
# 方法1：同时启动前后端
npm run dev

# 方法2：分别启动
# 终端1 - 后端
cd server
npm start

# 终端2 - 前端
npm start
```

### 4. 使用应用
1. 打开 http://localhost:3000
2. 点击右上角切换到"⚡ 真实API"
3. 点击 📎 上传图片或 DOCX 文档
4. 输入问题并发送

## 📋 支持的文件类型

| 类型 | 格式 | 大小限制 | 处理方式 | 状态 |
|------|------|---------|---------|------|
| 图片 | JPG, PNG, GIF | 5MB | Base64直传 | ✅ |
| 文档 | DOCX | 5MB | 提取文本 | ✅ |
| 文档 | PDF | 5MB | - | ❌ 待实现 |
| 文档 | DOC | 5MB | - | ❌ 待实现 |

## 💡 最佳实践

### 图片上传建议
1. **压缩大图片**：超过 2MB 的图片建议先压缩
2. **清晰度优先**：保证文字/细节清晰可见
3. **避免纯文本截图**：直接输入文字比截图更高效

### 文档上传建议
1. **纯文本最佳**：DOCX 会提取纯文本，格式会丢失
2. **避免复杂排版**：表格、图表等会被忽略
3. **PDF 转 DOCX**：如需分析 PDF，先转换为 DOCX

## 🔧 常见问题

### Q: 为什么图片上传后报 400 错误？
A: 检查以下几点：
- 图片是否超过 5MB？
- API Key 是否正确？
- 后端是否正常启动？

### Q: 为什么 PDF 不支持？
A: 当前只实现了 DOCX 解析。如需 PDF，可以：
- 手动转换为 DOCX 后上传
- 等待我们添加 pdf-parse 支持

### Q: 为什么文档分析不准确？
A: DOCX 只提取纯文本，会丢失：
- 图片、图表
- 表格结构
- 格式样式
建议：描述问题时尽量详细

## 🎯 下一步优化建议

### 短期（1-2天）
- [ ] 添加图片自动压缩（前端）
- [ ] 支持 PDF 文档解析
- [ ] 添加更详细的错误提示

### 中期（1周）
- [ ] 支持多张图片批量上传
- [ ] 添加历史对话记录
- [ ] 优化 UI/UX

### 长期（按需）
- [ ] 集成云存储（支持超大文件）
- [ ] 添加语音输入
- [ ] 多模型切换（GPT-4V、Claude 等）

## 📞 技术支持

遇到问题？
1. 查看后端终端日志（会显示详细错误）
2. 查看浏览器控制台（F12）
3. 检查 API Key 配额是否充足

---

**当前版本**：1.0.0  
**最后更新**：2026-01-20  
**模型版本**：GLM-4.6V
