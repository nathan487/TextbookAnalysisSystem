import React, { useState, useRef, useEffect, useCallback } from 'react';
import MessageList from './MessageList';
import InputArea from './InputArea';
import { sendMessageStream, simulateStreamResponse } from '../api/chatApi';
import { uploadFile, UploadedFile, isDeepSeekSupported } from '../utils/fileUtils';
import './ChatInterface.css';

interface Message {
  id: string;
  content: string;
  sender: 'user' | 'assistant';
  timestamp: Date;
  files?: UploadedFile[];
}

interface ModelInfo {
  id: string;
  name: string;
  description: string;
  max_tokens: number;
  vision: boolean;
  supports: string[];
  context_length?: number;  // æ·»åŠ å¯é€‰å­—æ®µ
}

const ChatInterface: React.FC = () => {
  const [messages, setMessages] = useState<Message[]>([
    {
      id: '1',
      content: 'ä½ å¥½ï¼æˆ‘æ˜¯AIåŠ©æ‰‹ï¼ŒåŸºäºQwen-VLå¤šæ¨¡æ€æ¨¡å‹ã€‚æˆ‘å¯ä»¥åˆ†æä½ ä¸Šä¼ çš„å›¾ç‰‡ã€PDFç­‰æ–‡ä»¶ï¼Œå¹¶è¿›è¡Œè§†è§‰ç†è§£ã€‚',
      sender: 'assistant',
      timestamp: new Date()
    }
  ]);
  const [isLoading, setIsLoading] = useState(false);
  const [isUsingRealAPI, setIsUsingRealAPI] = useState(false);
  const [abortController, setAbortController] = useState<AbortController | null>(null);
// åœ¨ ChatInterface.tsx ä¸­æ›´æ–°åˆå§‹æ¨¡å‹åˆ—è¡¨
const [availableModels, setAvailableModels] = useState<ModelInfo[]>([
  {
    id: 'deepseek-ai/DeepSeek-V3.2',
    name: 'DeepSeek-V3.2',
    description: 'å¼ºå¤§çš„ä»£ç å’Œæ–‡æœ¬åˆ†ææ¨¡å‹',
    max_tokens: 32768,
    vision: false,
    supports: ['ä»£ç ç”Ÿæˆ', 'æ–‡æœ¬åˆ†æ', 'æ–‡ä»¶åˆ†æ', 'æ•°å­¦æ¨ç†'],
    context_length: 128000
  },
  {
    id: 'deepseek-ai/DeepSeek-OCR',
    name: 'DeepSeek-OCR',
    description: 'è§†è§‰OCRæ¨¡å‹ï¼Œæ”¯æŒå›¾åƒæ–‡å­—è¯†åˆ«',
    max_tokens: 32768,
    vision: true,
    supports: ['å›¾åƒè¯†åˆ«', 'OCRæ–‡å­—æå–', 'æ–‡æœ¬åˆ†æ'],
    context_length: 128000
  },
  {
    id: 'Qwen/Qwen3-VL-32B-Instruct',
    name: 'Qwen3-VL-32B',
    description: 'å¤šæ¨¡æ€è§†è§‰æ¨¡å‹ï¼Œæ”¯æŒæ¨ç†å’Œæ–‡ä»¶åˆ†æ',
    max_tokens: 32768,
    vision: true,
    supports: ['è§†è§‰ç†è§£', 'å¤æ‚æ¨ç†', 'æ–‡ä»¶åˆ†æ', 'æ–‡æœ¬åˆ†æ'],
    context_length: 32000
  },
  {
    id: 'Qwen/Qwen2.5-VL-72B-Instruct',
    name: 'Qwen2.5-VL-72B',
    description: 'è§†è§‰è¯­è¨€æ¨¡å‹',
    max_tokens: 8192,
    vision: true,
    supports: ['å›¾åƒè¯†åˆ«', 'PDFåˆ†æ'],
    context_length: 8192
  },
  {
    id: 'Qwen/Qwen2.5-72B-Instruct',
    name: 'Qwen2.5-72B',
    description: 'çº¯æ–‡æœ¬è¯­è¨€æ¨¡å‹',
    max_tokens: 32768,
    vision: false,
    supports: ['æ–‡æœ¬å¯¹è¯'],
    context_length: 32768
  }
]);

// æ›´æ–°é»˜è®¤é€‰æ‹©çš„æ¨¡å‹
const [selectedModel, setSelectedModel] = useState<string>('deepseek-ai/DeepSeek-V3.2');
  
  const messagesEndRef = useRef<HTMLDivElement>(null);

  // è·å–å½“å‰é€‰æ‹©çš„æ¨¡å‹ä¿¡æ¯
  const getCurrentModel = useCallback(() => {
    return availableModels.find(model => model.id === selectedModel) || availableModels[0];
  }, [selectedModel, availableModels]);

  // è·å–æ¨¡å‹åˆ—è¡¨
  useEffect(() => {
    const fetchModels = async () => {
      try {
        const response = await fetch('http://localhost:3001/api/models');
        if (response.ok) {
          const data = await response.json();
          setAvailableModels(data.models);
          // å¦‚æœå½“å‰é€‰æ‹©çš„æ¨¡å‹ä¸åœ¨æ–°åˆ—è¡¨ä¸­ï¼Œé€‰æ‹©ç¬¬ä¸€ä¸ª
          if (!data.models.some((model: ModelInfo) => model.id === selectedModel)) {
            setSelectedModel(data.models[0]?.id || 'Qwen/Qwen2.5-VL-72B-Instruct');
          }
        }
      } catch (error) {
        console.error('è·å–æ¨¡å‹åˆ—è¡¨å¤±è´¥:', error);
      }
    };

    fetchModels();
  }, []);

  // è‡ªåŠ¨æ»šåŠ¨åˆ°åº•éƒ¨
  useEffect(() => {
    scrollToBottom();
  }, [messages]);

  const scrollToBottom = () => {
    messagesEndRef.current?.scrollIntoView({ behavior: 'smooth' });
  };

  // åœæ­¢ç”Ÿæˆå‡½æ•°
  const stopGeneration = useCallback(() => {
    if (abortController) {
      abortController.abort();
      setAbortController(null);
      setIsLoading(false);
      
      setMessages(prev => {
        const lastMessage = prev[prev.length - 1];
        if (lastMessage.sender === 'assistant' && lastMessage.content) {
          return [...prev.slice(0, -1), {
            ...lastMessage,
            content: lastMessage.content + '\n\n**[å·²åœæ­¢ç”Ÿæˆ]**'
          }];
        }
        return prev;
      });
      
      console.log('ç”Ÿæˆå·²åœæ­¢');
    }
  }, [abortController]);

  const handleSendMessage = async (content: string, files?: UploadedFile[]) => {
  if ((!content.trim() && (!files || files.length === 0)) || isLoading) return;

  // å¦‚æœæœ‰æ­£åœ¨è¿›è¡Œçš„ç”Ÿæˆï¼Œå…ˆåœæ­¢
  if (isLoading && abortController) {
    stopGeneration();
    await new Promise(resolve => setTimeout(resolve, 100));
  }

  // æ„å»ºæ¶ˆæ¯å†…å®¹
  let messageContent = content;
  if (files && files.length > 0) {
    const fileDescriptions = files.map(file => 
      `[${file.supportedByDeepSeek ? 'âœ…' : 'ğŸ“„'} æ–‡ä»¶: ${file.name} (${formatFileSize(file.size)})]`
    ).join('\n');
    messageContent = fileDescriptions + (content ? `\n\n${content}` : '');
  }

  // æ·»åŠ ç”¨æˆ·æ¶ˆæ¯
  const userMessage: Message = {
    id: Date.now().toString(),
    content: messageContent,
    sender: 'user',
    timestamp: new Date(),
    files: files || []
  };
  setMessages(prev => [...prev, userMessage]);
  setIsLoading(true);

  // åˆ›å»ºAIæ¶ˆæ¯
  const aiMessageId = (Date.now() + 1).toString();
  const aiMessage: Message = {
    id: aiMessageId,
    content: '',
    sender: 'assistant',
    timestamp: new Date()
  };
  setMessages(prev => [...prev, aiMessage]);

  // åˆ›å»ºAbortController
  const controller = new AbortController();
  setAbortController(controller);

  try {
    let fullResponse = '';
    
    const onChunk = (chunk: string) => {
      fullResponse += chunk;
      setMessages(prev => prev.map(msg => 
        msg.id === aiMessageId 
          ? { ...msg, content: fullResponse }
          : msg
      ));
    };

    const onComplete = () => {
      setIsLoading(false);
      setAbortController(null);
      setMessages(prev => prev.map(msg => 
        msg.id === aiMessageId 
          ? { ...msg, content: fullResponse.trim() }
          : msg
      ));
    };

    const onError = (error: string) => {
      if (error.includes('abort') || controller.signal.aborted) {
        setIsLoading(false);
        setAbortController(null);
        return;
      }
      
      console.error('Error:', error);
      setMessages(prev => prev.map(msg => 
        msg.id === aiMessageId 
          ? { 
              ...msg, 
              content: `æŠ±æ­‰ï¼Œæˆ‘é‡åˆ°äº†ä¸€äº›é—®é¢˜ï¼š${error}\n\nå·²åˆ‡æ¢ä¸ºæ¨¡æ‹Ÿæ¨¡å¼ï¼Œä½ å¯ä»¥ç»§ç»­èŠå¤©ã€‚` 
            }
          : msg
      ));
      setIsLoading(false);
      setAbortController(null);
      setIsUsingRealAPI(false);
    };

    if (isUsingRealAPI) {
      // çœŸå®APIæ¨¡å¼ - SiliconFlow
      // è·å–å½“å‰æ¨¡å‹ä¿¡æ¯
      const currentModel = getCurrentModel();
      const isVisionModel = currentModel.vision;
  
      // æ„å»ºæ–‡ä»¶æ•°æ® - ç¡®ä¿åŒ…å«æ­£ç¡®çš„è·¯å¾„ä¿¡æ¯
      const fileData = (files || []).map(file => {
       // æå–ç›¸å¯¹è·¯å¾„
      let filePath = '';
      if (file.url && file.url.includes('/uploads/')) {
          const urlParts = file.url.split('/uploads/');
        if (urlParts.length > 1) {
          filePath = '/uploads/' + urlParts[1];
        }
      }
    
      return {
        id: file.id,
        name: file.name,
        type: file.type,
        url: file.url,
        path: filePath, // æ·»åŠ ç›¸å¯¹è·¯å¾„
        deepSeekReady: file.deepSeekReady,
        supportedByDeepSeek: file.supportedByDeepSeek,
        category: getFileCategory(file.type)
      };
    });

    console.log('ğŸ“¤ å‘é€è¯·æ±‚æ•°æ®:', {
      message: content,
      files: fileData,
      model: selectedModel,
      max_tokens: 4000,
      isVisionModel: isVisionModel
    });

    const requestData = {
      message: content,
      files: fileData,
      model: selectedModel,
      max_tokens: 4000
    };

      const response = await fetch('http://localhost:3001/api/chat/stream', {
        method: 'POST',
        headers: {
          'Content-Type': 'application/json',
        },
        body: JSON.stringify(requestData),
        signal: controller.signal
      });

      if (!response.ok) {
        const errorText = await response.text();
        throw new Error(`HTTP error! status: ${response.status}: ${errorText}`);
      }

      // å¤„ç†æµå¼å“åº”
      const reader = response.body?.getReader();
      const decoder = new TextDecoder('utf-8');
      let buffer = '';

      if (!reader) {
        onError('æ— æ³•è¯»å–å“åº”æµ');
        return;
      }

      try {
        while (true) {
          const { done, value } = await reader.read();
          if (done) {
            if (buffer.trim()) {
              const lines = buffer.split('\n');
              for (const line of lines) {
                if (line.startsWith('data: ')) {
                  processLine(line.slice(6), onChunk, onError);
                }
              }
            }
            onComplete();
            break;
          }

          buffer += decoder.decode(value, { stream: true });
          const lines = buffer.split('\n');
          buffer = lines.pop() || '';

          for (const line of lines) {
            if (line.startsWith('data: ')) {
              processLine(line.slice(6), onChunk, onError);
            }
          }
        }
      } catch (error) {
        if (error instanceof Error && error.name === 'AbortError') {
          throw error;
        }
        console.error('Stream reading error:', error);
        onError('è¯»å–æ•°æ®æµæ—¶å‡ºé”™');
      } finally {
        reader.releaseLock();
      }

    } else {
      // æ¨¡æ‹Ÿæ¨¡å¼
      await simulateStreamResponse(
        messageContent, 
        onChunk, 
        onComplete,
        controller
      );
    }

  } catch (error) {
    if (error instanceof Error && (error.name === 'AbortError' || error.message.includes('aborted'))) {
      setIsLoading(false);
      setAbortController(null);
      return;
    }
    
    console.error('Error:', error);
    setMessages(prev => prev.map(msg => 
      msg.id === aiMessageId 
        ? { 
            ...msg, 
            content: 'æŠ±æ­‰ï¼Œç½‘ç»œè¿æ¥å‡ºç°é—®é¢˜ï¼Œè¯·ç¨åå†è¯•ã€‚' 
          }
        : msg
    ));
    setIsLoading(false);
    setAbortController(null);
    setIsUsingRealAPI(false);
  }
};

// è¾…åŠ©å‡½æ•°ï¼šè·å–æ–‡ä»¶åˆ†ç±»
const getFileCategory = (mimeType: string): string => {
  if (mimeType.startsWith('image/')) return 'images';
  if (mimeType === 'application/pdf') return 'pdfs';
  if (mimeType.startsWith('audio/')) return 'audio';
  return 'others';
};
  

  // å¤„ç†SSEæ•°æ®è¡Œ
  const processLine = (
    dataStr: string,
    onChunk: (chunk: string) => void,
    onError: (error: string) => void
  ) => {
    if (dataStr.trim() === '') return;
    
    if (dataStr === '[DONE]') {
      return;
    }

    try {
      const data = JSON.parse(dataStr);
      
      if (data.type === 'chunk' && data.content) {
        onChunk(data.content);
      } else if (data.type === 'error') {
        onError(data.message || 'æœªçŸ¥é”™è¯¯');
      }
    } catch (e) {
      console.warn('Failed to parse SSE data:', dataStr, e);
    }
  };

  // è¾…åŠ©å‡½æ•°
  const formatFileSize = (bytes: number): string => {
    if (bytes === 0) return '0 Bytes';
    const k = 1024;
    const sizes = ['Bytes', 'KB', 'MB', 'GB'];
    const i = Math.floor(Math.log(bytes) / Math.log(k));
    return parseFloat((bytes / Math.pow(k, i)).toFixed(2)) + ' ' + sizes[i];
  };

  // é”®ç›˜å¿«æ·é”®æ”¯æŒ
  useEffect(() => {
    const handleKeyDown = (e: KeyboardEvent) => {
      if ((e.ctrlKey && e.key === '.') || e.key === 'Escape') {
        if (isLoading) {
          e.preventDefault();
          stopGeneration();
        }
      }
    };

    window.addEventListener('keydown', handleKeyDown);
    return () => window.removeEventListener('keydown', handleKeyDown);
  }, [isLoading, stopGeneration]);

  const handleClearChat = () => {
    if (isLoading && abortController) {
      stopGeneration();
    }
    
    setMessages([{
      id: Date.now().toString(),
      content: 'å¯¹è¯å·²æ¸…ç©ºã€‚æœ‰ä»€ä¹ˆå¯ä»¥å¸®ä½ çš„å—ï¼Ÿ',
      sender: 'assistant',
      timestamp: new Date()
    }]);
  };

  const toggleAPI = () => {
    if (isLoading && abortController) {
      stopGeneration();
    }
    
    setIsUsingRealAPI(!isUsingRealAPI);
    const currentModel = getCurrentModel();
    const status = !isUsingRealAPI ? 'çœŸå®Qwen-VL API' : 'æ¨¡æ‹Ÿæ¨¡å¼';
    const features = currentModel.vision ? 'âœ“ æ”¯æŒå›¾åƒå’Œæ–‡ä»¶åˆ†æ' : 'âœ“ æ”¯æŒæ–‡æœ¬å¯¹è¯';
    alert(`å·²åˆ‡æ¢åˆ°${status}\næ¨¡å‹: ${currentModel.name}\n${features}`);
  };

  const handleModelChange = (modelId: string) => {
    if (isLoading && abortController) {
      stopGeneration();
    }

    const newModel = availableModels.find(m => m.id === modelId);
    if (newModel) {
      setSelectedModel(modelId);

      // æ˜¾ç¤ºæ¨¡å‹åˆ‡æ¢æç¤º
      const modelName = newModel.name;
      const capabilities = newModel.supports.join(' | ');
      const contextLength = newModel.context_length ? `ä¸Šä¸‹æ–‡: ${(newModel.context_length / 1000).toFixed(0)}K` : '';

      console.log(`åˆ‡æ¢æ¨¡å‹åˆ°: ${modelName} (${capabilities}) ${contextLength}`);

      // åœ¨ç•Œé¢ä¸Šæ˜¾ç¤ºç®€çŸ­æç¤º
      if (modelId.includes('DeepSeek-V3.2')) {
        console.log('âœ“ é€‰æ‹© DeepSeek-V3.2 - ä¸“ä¸ºä»£ç å’Œæ–‡æœ¬ã€æ–‡ä»¶åˆ†æä¼˜åŒ–');
      } else if (modelId.includes('DeepSeek-OCR')) {
        console.log('âœ“ é€‰æ‹© DeepSeek-OCR - æ”¯æŒå›¾åƒæ–‡å­—è¯†åˆ«');
      } else if (modelId.includes('Qwen3-VL-32B')) {
        console.log('âœ“ é€‰æ‹© Qwen3-VL-32B - å¤šæ¨¡æ€è§†è§‰æ¨ç†');
      }
    }
  };

  return (
    <div className="chat-interface">
      <div className="chat-header">
        <div className="header-left">
          <h1>ğŸ¤– Qwen-VL AIåŠ©æ‰‹</h1>
          <div className="model-info">
            <select 
              className="model-select"
              value={selectedModel}
              onChange={(e) => handleModelChange(e.target.value)}
              disabled={isLoading}
              title="é€‰æ‹©AIæ¨¡å‹"
            >
              {availableModels.map(model => (
                <option key={model.id} value={model.id}>
                  {model.name} {model.vision ? '(å¤šæ¨¡æ€)' : '(çº¯æ–‡æœ¬)'}
                </option>
              ))}
            </select>
            
            <span className="status-indicator">
              â— {isUsingRealAPI ? 'çœŸå®API' : 'æ¨¡æ‹Ÿæ¨¡å¼'}
              {isUsingRealAPI && getCurrentModel().vision && ' âœ“ å›¾åƒåˆ†æ'}
            </span>
            
            {isLoading && (
              <button 
                className="stop-button"
                onClick={stopGeneration}
                title="åœæ­¢ç”Ÿæˆ (Esc æˆ– Ctrl+.)"
              >
                â¹ï¸ åœæ­¢ç”Ÿæˆ
              </button>
            )}
            <button 
              className="api-toggle-button"
              onClick={toggleAPI}
              title={isUsingRealAPI ? 'åˆ‡æ¢åˆ°æ¨¡æ‹Ÿæ¨¡å¼' : 'åˆ‡æ¢åˆ°çœŸå®API'}
              disabled={isLoading}
            >
              {isUsingRealAPI ? 'ğŸ”Œ æ¨¡æ‹Ÿæ¨¡å¼' : 'âš¡ çœŸå®API'}
            </button>
          </div>
        </div>
        <button 
          className="clear-button"
          onClick={handleClearChat}
          title="æ¸…ç©ºå¯¹è¯"
          disabled={isLoading}
        >
          æ¸…ç©ºå¯¹è¯
        </button>
      </div>
      
      <div className="chat-messages-container">
        <MessageList messages={messages} isLoading={isLoading} />
        <div ref={messagesEndRef} />
      </div>
      
      <InputArea 
        onSendMessage={handleSendMessage}
        isLoading={isLoading}
        onStopGeneration={stopGeneration}
      />
      
      {isUsingRealAPI && (
        <div className="api-notice">
          âš¡ {getCurrentModel().name} æ¨¡å¼ | 
          {getCurrentModel().vision ? ' æ”¯æŒå›¾åƒ/æ–‡ä»¶åˆ†æ' : ' çº¯æ–‡æœ¬å¯¹è¯'} | 
          æœ€å¤§é•¿åº¦: {getCurrentModel().max_tokens} tokens |
          {isLoading && ' æŒ‰ Esc åœæ­¢ç”Ÿæˆ'}
        </div>
      )}
    </div>
  );
};

export default ChatInterface;